<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mihir Inamdar | NLP & Computer Vision Researcher</title>
    <meta name="description" content="Portfolio of Mihir Inamdar, AI Researcher specializing in NLP and computer vision, seeking a Predoctoral Young Investigator position at Allen AI.">
    <meta name="author" content="Mihir Inamdar">
    
    <meta property="og:title" content="Mihir Inamdar | NLP & Computer Vision Researcher">
    <meta property="og:description" content="Portfolio of Mihir Inamdar, AI Researcher specializing in NLP and computer vision, seeking a Predoctoral Young Investigator position at Allen AI.">
    <meta property="og:type" content="website">
    <meta property="og:image" content="https://avatars.githubusercontent.com/u/39341893?v=4">
    
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700&family=Roboto+Mono:wght@400;500&display=swap" rel="stylesheet">
</head>
<body>
    <header>
        <div class="container">
            <div class="profile">
                <img src="https://avatars.githubusercontent.com/u/39341893?v=4" alt="Mihir Inamdar" class="profile-img">
                <div class="profile-text">
                    <h1>Mihir Inamdar</h1>
                    <h2>NLP & Computer Vision Researcher</h2>
                    <div class="tagline">Predoctoral Research Candidate | Machine Learning Engineer | AI Researcher</div>
                </div>
            </div>
            <nav>
                <ul>
                    <li><a href="#research-focus" class="nav-link">Research Focus</a></li>
                    <li><a href="#publications" class="nav-link">Publications</a></li>
                    <li><a href="#projects" class="nav-link">Projects</a></li>
                    <li><a href="#experience" class="nav-link">Experience</a></li>
                    <li><a href="#skills" class="nav-link">Skills</a></li>
                    <li><a href="#education" class="nav-link">Education</a></li>
                    <li><a href="#motivation" class="nav-link">Research Motivation</a></li>
                    <li><a href="#contact" class="nav-link">Contact</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <section id="research-focus" class="section">
        <div class="container">
            <h2 class="section-title">Research Focus</h2>
            <div class="research-content">
                <p class="research-intro">My research focuses on advancing the capabilities of AI systems in understanding and processing multimodal information, with particular emphasis on the intersection of natural language processing and computer vision. I am passionate about developing models that can effectively reason about visual and textual data in an integrated manner, enabling more sophisticated human-AI interaction and knowledge extraction.</p>
                
                <div class="research-areas">
                    <div class="research-area">
                        <div class="research-icon"><i class="fas fa-comment-dots"></i></div>
                        <h3>Natural Language Processing</h3>
                        <p>Developing and fine-tuning transformer-based models for document understanding, information extraction, and question answering. My work focuses on improving model efficiency and performance in domain-specific applications.</p>
                    </div>
                    <div class="research-area">
                        <div class="research-icon"><i class="fas fa-eye"></i></div>
                        <h3>Computer Vision</h3>
                        <p>Exploring advanced architectures for visual understanding, with a focus on document image analysis, scene understanding, and human-centric computer vision applications that can operate effectively in real-world scenarios.</p>
                    </div>
                    <div class="research-area">
                        <div class="research-icon"><i class="fas fa-project-diagram"></i></div>
                        <h3>Multimodal Learning</h3>
                        <p>Investigating methods for effective integration of information across modalities, particularly in document visual question answering and multimodal reasoning tasks that require sophisticated understanding of both visual and textual elements.</p>
                    </div>
                    <div class="research-area">
                        <div class="research-icon"><i class="fas fa-file-alt"></i></div>
                        <h3>Document AI</h3>
                        <p>Building systems for automated document processing, understanding, and information extraction that can handle complex layouts, diverse document types, and challenging visual conditions.</p>
                    </div>
                </div>
                
                <div class="research-philosophy">
                    <h3>Research Philosophy</h3>
                    <p>I approach research with a dual focus on advancing the theoretical understanding of AI systems and developing practical applications that address real-world challenges. My methodology emphasizes rigorous experimentation, careful analysis of results, and iterative refinement of approaches based on empirical findings. I believe in the importance of reproducible research and open collaboration to accelerate progress in the field.</p>
                    <p>My work is guided by the principle that truly effective AI systems must be able to understand and reason about information in ways that mirror human cognitive processes, while also being efficient, robust, and adaptable to diverse contexts and domains.</p>
                </div>
            </div>
        </div>
    </section>

    <section id="publications" class="section">
        <div class="container">
            <h2 class="section-title">Publications & Research Experience</h2>
            <div class="publications-content">
                <div class="featured-publication">
                    <h3>Featured Publication</h3>
                    <div class="publication-item">
                        <h4>Improving Document Visual Question Answering with Multi-scale Attention Mechanisms</h4>
                        <p class="publication-venue">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR) - 2024</p>
                        <p class="publication-description">This research introduces a novel multi-scale attention mechanism that significantly improves document visual question answering performance by effectively capturing both local and global context in document images. The approach demonstrates superior performance on benchmark datasets by addressing the challenge of integrating information across different visual scales and textual elements in complex document layouts.</p>
                        <div class="publication-keywords">
                            <span class="keyword">document VQA</span>
                            <span class="keyword">multi-scale attention</span>
                            <span class="keyword">transformers</span>
                            <span class="keyword">computer vision</span>
                        </div>
                    </div>
                </div>
                
                <div class="research-experience">
                    <h3>Research Experience</h3>
                    <div class="research-item">
                        <h4>Graduate ML Research Fellow</h4>
                        <h5>CVIT, IIIT Hyderabad, India (Mar 2024 - Aug 2024)</h5>
                        <p>Led research on document understanding and information extraction, focusing on developing novel approaches for processing complex document layouts and improving OCR accuracy through advanced image pre-processing and post-correction techniques.</p>
                        <ul class="research-highlights">
                            <li>Processed 50,000+ scanned documents using advanced image pre-processing techniques, reducing OCR errors by 20%</li>
                            <li>Designed and implemented a post-OCR error correction pipeline by fine-tuning transformer-based models</li>
                            <li>Contributed to a patent-pending method for complex layout analysis in document understanding</li>
                            <li>Presented research findings at internal symposiums, receiving recognition for innovative approaches</li>
                        </ul>
                    </div>
                    
                    <div class="research-item">
                        <h4>Independent Research Projects</h4>
                        <p>Conducted self-directed research in multimodal learning and document AI, resulting in several projects that explore the integration of vision and language models for improved document understanding and information extraction.</p>
                        <ul class="research-highlights">
                            <li>Fine-tuned Florence-2 model on the DocVQA dataset to enhance document understanding capabilities</li>
                            <li>Developed a RAG-based system for mathematics learning and problem-solving with 100% accuracy in trigonometry</li>
                            <li>Created an AI-powered research assistant leveraging OpenAI's Agents SDK for comprehensive web research</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="projects" class="section">
        <div class="container">
            <h2 class="section-title">Research Projects</h2>
            <div class="project-intro">
                <p>My research portfolio includes projects across natural language processing, computer vision, and multimodal learning. Each project addresses specific research challenges and demonstrates my approach to developing innovative AI solutions.</p>
            </div>
            
            <div class="project-categories">
                <h3>NLP Projects</h3>
                <div class="projects-grid">
                    <div class="project-card">
                        <h4>ResearchGeniusAI</h4>
                        <p class="project-tech">AI-Powered Research Assistant</p>
                        <div class="project-research">
                            <h5>Research Problem:</h5>
                            <p>Developing an automated system for comprehensive literature review and knowledge synthesis that can understand research questions and autonomously gather relevant information.</p>
                        </div>
                        <ul class="project-highlights">
                            <li>Leveraged OpenAI's Agents SDK and Firecrawl for comprehensive web research capabilities</li>
                            <li>Implemented deep web research functionality with automatic content extraction and synthesis</li>
                            <li>Developed methods for evaluating information quality and relevance in research contexts</li>
                        </ul>
                        <div class="project-keywords">
                            <span class="keyword">OpenAI Agents</span>
                            <span class="keyword">Web Research</span>
                            <span class="keyword">Knowledge Synthesis</span>
                        </div>
                        <div class="project-links">
                            <a href="https://github.com/inamdarmihir/ResearchGeniusAI" class="btn github-btn"><i class="fab fa-github"></i> View on GitHub</a>
                        </div>
                    </div>
                    
                    <div class="project-card">
                        <h4>Math-Prof-AI</h4>
                        <p class="project-tech">Mathematics Learning Agent</p>
                        <div class="project-research">
                            <h5>Research Problem:</h5>
                            <p>Creating an AI system capable of domain-specific mathematical reasoning and step-by-step problem solving across multiple mathematical domains.</p>
                        </div>
                        <ul class="project-highlights">
                            <li>Built an agentic RAG-based system for mathematics learning across algebra, calculus, and trigonometry</li>
                            <li>Achieved 100% accuracy in trigonometry and 66.7% accuracy in algebra with sophisticated benchmarking</li>
                            <li>Developed methods for structured mathematical knowledge representation and retrieval</li>
                        </ul>
                        <div class="project-keywords">
                            <span class="keyword">RAG System</span>
                            <span class="keyword">Mathematics AI</span>
                            <span class="keyword">Agentic Learning</span>
                        </div>
                        <div class="project-links">
                            <a href="https://github.com/inamdarmihir/math-prof-ai" class="btn github-btn"><i class="fab fa-github"></i> View on GitHub</a>
                        </div>
                    </div>
                    
                    <div class="project-card">
                        <h4>Multilingual NER System</h4>
                        <p class="project-tech">Named Entity Recognition for Code-Switched Text</p>
                        <div class="project-research">
                            <h5>Research Problem:</h5>
                            <p>Addressing the challenge of named entity recognition in code-switched text containing multiple Indian languages, where traditional monolingual models fail.</p>
                        </div>
                        <ul class="project-highlights">
                            <li>Developed a specialized NER system for code-switched text in Indian languages</li>
                            <li>Fine-tuned XLM-RoBERTa on custom datasets to handle multilingual entity recognition</li>
                            <li>Implemented techniques for handling script variations and transliteration challenges</li>
                        </ul>
                        <div class="project-keywords">
                            <span class="keyword">Multilingual NLP</span>
                            <span class="keyword">Code-Switching</span>
                            <span class="keyword">Named Entity Recognition</span>
                        </div>
                        <div class="project-links">
                            <a href="https://github.com/inamdarmihir" class="btn github-btn"><i class="fab fa-github"></i> View on GitHub</a>
                        </div>
                    </div>
                </div>
                
                <h3>Computer Vision Projects</h3>
                <div class="projects-grid">
                    <div class="project-card">
                        <h4>Florence-2-DocVQA</h4>
                        <p class="project-tech">Document Visual Question Answering</p>
                        <div class="project-research">
                            <h5>Research Problem:</h5>
                            <p>Enhancing multimodal models to better understand and reason about document images, addressing the challenges of complex layouts and diverse document types.</p>
                        </div>
                        <ul class="project-highlights">
                            <li>Fine-tuned Florence-2 model on the DocVQA dataset to enhance document understanding capabilities</li>
                            <li>Optimized the architecture for document image visual question answering with significant accuracy improvements</li>
                            <li>Implemented advanced data augmentation techniques to enhance model robustness</li>
                        </ul>
                        <div class="project-keywords">
                            <span class="keyword">Document AI</span>
                            <span class="keyword">Computer Vision</span>
                            <span class="keyword">Multimodal</span>
                            <span class="keyword">SOTA Models</span>
                        </div>
                        <div class="project-links">
                            <a href="https://github.com/inamdarmihir/Florence-2-DocVQA" class="btn github-btn"><i class="fab fa-github"></i> View on GitHub</a>
                        </div>
                    </div>
                    
                    <div class="project-card">
                        <h4>Wav2Lip</h4>
                        <p class="project-tech">Audio-Video Lip Synchronization</p>
                        <div class="project-research">
                            <h5>Research Problem:</h5>
                            <p>Developing methods for accurate lip synchronization in videos with mismatched audio, addressing challenges in temporal alignment and visual realism.</p>
                        </div>
                        <ul class="project-highlights">
                            <li>Implemented an advanced lip-synchronization model that accurately aligns speech audio with video content</li>
                            <li>Enhanced the original Wav2Lip architecture to handle various speech patterns and facial orientations</li>
                            <li>Researched techniques for improving visual quality and reducing artifacts in synthesized videos</li>
                        </ul>
                        <div class="project-keywords">
                            <span class="keyword">Computer Vision</span>
                            <span class="keyword">Audio Processing</span>
                            <span class="keyword">GAN</span>
                            <span class="keyword">Human-AI Interface</span>
                        </div>
                        <div class="project-links">
                            <a href="https://github.com/inamdarmihir/wav2lip" class="btn github-btn"><i class="fab fa-github"></i> View on GitHub</a>
                        </div>
                    </div>
                    
                    <div class="project-card">
                        <h4>Face Fusion for XR</h4>
                        <p class="project-tech">Extended Reality Applications</p>
                        <div class="project-research">
                            <h5>Research Problem:</h5>
                            <p>Creating realistic face-swapping technology for extended reality applications that maintains identity consistency and high visual fidelity.</p>
                        </div>
                        <ul class="project-highlights">
                            <li>Developed a face fusion solution for XR applications by fine-tuning GANs and autoencoders</li>
                            <li>Achieved realistic, high-resolution face-swapping that reduced post-production time by 40%</li>
                            <li>Researched methods for preserving identity features while adapting to target expressions</li>
                        </ul>
                        <div class="project-keywords">
                            <span class="keyword">Extended Reality</span>
                            <span class="keyword">GANs</span>
                            <span class="keyword">Face Recognition</span>
                            <span class="keyword">Identity Preservation</span>
                        </div>
                        <div class="project-links">
                            <a href="https://github.com/inamdarmihir" class="btn github-btn"><i class="fab fa-github"></i> View on GitHub</a>
                        </div>
                    </div>
                </div>
                
                <h3>Multimodal Projects</h3>
                <div class="projects-grid">
                    <div class="project-card">
                        <h4>Document Classification System</h4>
                        <p class="project-tech">IndoML Datathon Project</p>
                        <div class="project-research">
                            <h5>Research Problem:</h5>
                            <p>Developing efficient methods for classifying diverse document types based on both visual and textual features, addressing the challenge of heterogeneous document formats.</p>
                        </div>
                        <ul class="project-highlights">
                            <li>Implemented document classification using Inception ResNetV2, achieving 90.8% accuracy</li>
                            <li>Developed techniques for handling imbalanced document classes and varying image qualities</li>
                            <li>Researched methods for combining visual and textual features for improved classification</li>
                        </ul>
                        <div class="project-keywords">
                            <span class="keyword">Document Classification</span>
                            <span class="keyword">Transfer Learning</span>
                            <span class="keyword">Computer Vision</span>
                            <span class="keyword">Multimodal</span>
                        </div>
                        <div class="project-links">
                            <a href="https://github.com/inamdarmihir/iitgn-indoml" class="btn github-btn"><i class="fab fa-github"></i> View on GitHub</a>
                        </div>
                    </div>
                    
                    <div class="project-card">
                        <h4>Intent Recognition System</h4>
                        <p class="project-tech">Multilingual NLP Application</p>
                        <div class="project-research">
                            <h5>Research Problem:</h5>
                            <p>Addressing the challenge of accurate intent recognition in multilingual contexts, particularly for e-commerce and customer service applications.</p>
                        </div>
                        <ul class="project-highlights">
                            <li>Fine-tuned XLM-RoBERTa on the Amazon Science dataset for intent recognition</li>
                            <li>Developed methods for handling linguistic variations and domain-specific terminology</li>
                            <li>Researched techniques for improving model generalization across languages</li>
                        </ul>
                        <div class="project-keywords">
                            <span class="keyword">Intent Recognition</span>
                            <span class="keyword">Multilingual NLP</span>
                            <span class="keyword">Transfer Learning</span>
                            <span class="keyword">E-commerce</span>
                        </div>
                        <div class="project-links">
                            <a href="https://github.com/inamdarmihir" class="btn github-btn"><i class="fab fa-github"></i> View on GitHub</a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="experience" class="section">
        <div class="container">
            <h2 class="section-title">Professional Experience</h2>
            <div class="timeline">
                <div class="timeline-item">
                    <div class="timeline-date">Oct 2024 - Present</div>
                    <div class="timeline-content">
                        <h3>ML Engineer</h3>
                        <h4>Quoppo Ventures, Pune, India</h4>
                        <p class="experience-summary">Leading research and development of AI systems for location tracking, extended reality, and automated information extraction, with a focus on developing novel approaches and bringing research innovations to production.</p>
                        <ul>
                            <li>Designed and implemented a real-time location system (RTLS) leveraging a hybrid LSTM and MesNet model, significantly enhancing indoor positioning accuracy by 30% using advanced data fusion techniques.</li>
                            <li>Developed a face fusion solution for extended reality (XR) applications by fine-tuning GANs and autoencoders, enabling realistic, high-resolution face-swapping that reduced post-production time by 40%.</li>
                            <li>Engineered AI-powered automation for a venture funding research platform, integrating NLP-based document summarization and entity recognition, leading to a 25% improvement in data-driven decision-making efficiency.</li>
                            <li>Led a team of 3 junior engineers in implementing MLOps best practices, reducing model deployment time from days to hours.</li>
                        </ul>
                        <div class="tech-used">
                            <span class="tech-label">Research Areas:</span>
                            <span class="tech-item">Computer Vision</span>
                            <span class="tech-item">NLP</span>
                            <span class="tech-item">Deep Learning</span>
                            <span class="tech-item">GANs</span>
                            <span class="tech-item">LSTM</span>
                        </div>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-date">Mar 2024 - Aug 2024</div>
                    <div class="timeline-content">
                        <h3>Graduate ML Research Fellow</h3>
                        <h4>CVIT, IIIT Hyderabad, India</h4>
                        <p class="experience-summary">Conducted research on document understanding and information extraction, focusing on developing novel approaches for processing complex document layouts and improving OCR accuracy.</p>
                        <ul>
                            <li>Led the processing of 50,000+ scanned documents utilizing advanced image pre-processing techniques, reducing OCR errors by 20% and enhancing text extraction quality.</li>
                            <li>Designed and implemented a post-OCR error correction pipeline by fine-tuning transformer-based models, improving data extraction accuracy by 15% for historical and low-quality scanned documents.</li>
                            <li>Collaborated with a cross-disciplinary team of researchers to develop novel approaches for document understanding, contributing to a patent-pending method for complex layout analysis.</li>
                            <li>Presented research findings at two internal symposiums, receiving recognition for innovative approaches to document AI challenges.</li>
                        </ul>
                        <div class="tech-used">
                            <span class="tech-label">Research Areas:</span>
                            <span class="tech-item">Document AI</span>
                            <span class="tech-item">OCR</span>
                            <span class="tech-item">Transformers</span>
                            <span class="tech-item">Computer Vision</span>
                        </div>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-date">Oct 2023 - Feb 2024</div>
                    <div class="timeline-content">
                        <h3>NLP and Backend Intern</h3>
                        <h4>Textify AI, Indore, India</h4>
                        <p class="experience-summary">Developed NLP solutions for automated ticket classification and sentiment analysis, focusing on improving efficiency and accuracy of language understanding systems.</p>
                        <ul>
                            <li>Developed a machine learning-based ticket classification system using BERT and fine-tuned transformers, achieving a 99.8% F1-score and automating customer support triage.</li>
                            <li>Built a real-time stock recommendation engine leveraging NLP techniques and sentiment analysis, leading to a 35% increase in user engagement with personalized investment insights.</li>
                            <li>Researched and implemented methods for improving model performance on domain-specific language understanding tasks.</li>
                        </ul>
                        <div class="tech-used">
                            <span class="tech-label">Research Areas:</span>
                            <span class="tech-item">NLP</span>
                            <span class="tech-item">BERT</span>
                            <span class="tech-item">Sentiment Analysis</span>
                            <span class="tech-item">Classification</span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="skills" class="section">
        <div class="container">
            <h2 class="section-title">Research Skills & Expertise</h2>
            <div class="skills-container">
                <div class="skills-category">
                    <h3>Research Methodologies</h3>
                    <div class="skill-tags">
                        <span class="skill-tag">Experimental Design</span>
                        <span class="skill-tag">Data Analysis</span>
                        <span class="skill-tag">Literature Review</span>
                        <span class="skill-tag">Hypothesis Testing</span>
                        <span class="skill-tag">Ablation Studies</span>
                        <span class="skill-tag">Benchmarking</span>
                    </div>
                </div>
                <div class="skills-category">
                    <h3>Machine Learning & AI</h3>
                    <div class="skill-tags">
                        <span class="skill-tag">Deep Learning</span>
                        <span class="skill-tag">Natural Language Processing</span>
                        <span class="skill-tag">Computer Vision</span>
                        <span class="skill-tag">Transformers</span>
                        <span class="skill-tag">GANs</span>
                        <span class="skill-tag">LSTM</span>
                        <span class="skill-tag">Transfer Learning</span>
                        <span class="skill-tag">Fine-Tuning LLMs</span>
                    </div>
                </div>
                <div class="skills-category">
                    <h3>Frameworks & Libraries</h3>
                    <div class="skill-tags">
                        <span class="skill-tag">PyTorch</span>
                        <span class="skill-tag">TensorFlow</span>
                        <span class="skill-tag">Hugging Face</span>
                        <span class="skill-tag">Langchain</span>
                        <span class="skill-tag">OpenCV</span>
                        <span class="skill-tag">scikit-learn</span>
                        <span class="skill-tag">WandB</span>
                        <span class="skill-tag">MLflow</span>
                    </div>
                </div>
                <div class="skills-category">
                    <h3>Programming & Development</h3>
                    <div class="skill-tags">
                        <span class="skill-tag">Python</span>
                        <span class="skill-tag">Java</span>
                        <span class="skill-tag">SQL</span>
                        <span class="skill-tag">Docker</span>
                        <span class="skill-tag">Git</span>
                        <span class="skill-tag">AWS</span>
                        <span class="skill-tag">MLOps</span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="education" class="section">
        <div class="container">
            <h2 class="section-title">Education & Academic Background</h2>
            <div class="education-content">
                <div class="education-item">
                    <h3>Bachelor of Engineering, Information Technology</h3>
                    <h4>Pune Institute of Computer Technology, Pune, India</h4>
                    <p class="education-date">2020 - 2024</p>
                    <p class="education-description">Focused on machine learning, artificial intelligence, and software engineering with specialized coursework in deep learning, computer vision, and natural language processing.</p>
                    <div class="relevant-coursework">
                        <h5>Relevant Coursework:</h5>
                        <div class="course-tags">
                            <span class="course-tag">Machine Learning</span>
                            <span class="course-tag">Deep Learning</span>
                            <span class="course-tag">Computer Vision</span>
                            <span class="course-tag">Natural Language Processing</span>
                            <span class="course-tag">Data Structures & Algorithms</span>
                            <span class="course-tag">Advanced Mathematics</span>
                        </div>
                    </div>
                </div>
                <div class="education-item">
                    <h3>Technical Certifications</h3>
                    <ul class="certification-list">
                        <li>Deep Learning Specialization, Coursera</li>
                        <li>Machine Learning Operations (MLOps), Coursera</li>
                        <li>Natural Language Processing with Transformers, Hugging Face</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <section id="motivation" class="section">
        <div class="container">
            <h2 class="section-title">Research Motivation for Allen AI</h2>
            <div class="motivation-content">
                <p>My research journey is driven by a passion for developing AI systems that can understand and reason about multimodal information in ways that mirror human cognitive processes. Allen AI's mission to contribute to humanity through high-impact AI research and engineering perfectly aligns with my own research goals and values.</p>
                
                <div class="motivation-areas">
                    <h3>Why Allen AI?</h3>
                    <p>Allen AI's Predoctoral Young Investigator program represents an ideal opportunity for me to prepare for graduate-level research while contributing to cutting-edge projects in natural language processing and computer vision. I am particularly drawn to the institute's focus on:</p>
                    <ul>
                        <li><strong>Perceptual Reasoning and Interaction Research (PRIOR)</strong> - My work in document visual question answering and multimodal learning aligns directly with PRIOR's mission to advance computer vision systems that see, explore, learn, and reason about the world.</li>
                        <li><strong>Collaborative Research Environment</strong> - The opportunity to work alongside leading researchers and contribute to publications at top venues would significantly enhance my research capabilities and prepare me for doctoral studies.</li>
                        <li><strong>Impactful Applications</strong> - Allen AI's focus on developing AI systems with real-world impact resonates with my own research philosophy of balancing theoretical advancement with practical applications.</li>
                    </ul>
                </div>
                
                <div class="research-interests-ai2">
                    <h3>Research Interests at Allen AI</h3>
                    <p>Based on Allen AI's current research directions, I am particularly interested in contributing to:</p>
                    <ul>
                        <li><strong>Language and Vision Integration</strong> - Developing models that can effectively reason about visual and textual data in an integrated manner, building on my experience with document VQA and multimodal systems.</li>
                        <li><strong>Visual Knowledge Extraction</strong> - Advancing methods for extracting structured knowledge from visual content, leveraging my background in document AI and information extraction.</li>
                        <li><strong>Representation Learning</strong> - Exploring novel approaches to learning robust and transferable representations across modalities, building on my experience with transformer models and transfer learning.</li>
                    </ul>
                </div>
                
                <div class="long-term-vision">
                    <h3>Long-term Research Vision</h3>
                    <p>My goal is to pursue a PhD focused on advancing multimodal AI systems that can understand, reason about, and generate content across different modalities. The Allen AI Predoctoral Young Investigator position would provide invaluable preparation for this journey by allowing me to develop strong research skills, contribute to meaningful projects, and build a foundation for future academic pursuits.</p>
                    <p>I am committed to conducting research that not only advances the theoretical understanding of AI systems but also leads to practical applications that can make a positive impact on society. Allen AI's emphasis on both research excellence and real-world impact makes it the ideal environment for pursuing these goals.</p>
                </div>
            </div>
        </div>
    </section>

    <section id="contact" class="section">
        <div class="container">
            <h2 class="section-title">Get In Touch</h2>
            <div class="contact-content">
                <p>I'm eager to discuss research opportunities, collaborations, and how my background and interests align with Allen AI's mission. Please feel free to reach out through any of the channels below.</p>
                <div class="social-links">
                    <a href="mailto:mihir@example.com" class="social-btn"><i class="fas fa-envelope"></i> Email</a>
                    <a href="https://linkedin.com/in/inamdarmihir" target="_blank" class="social-btn"><i class="fab fa-linkedin"></i> LinkedIn</a>
                    <a href="https://github.com/inamdarmihir" target="_blank" class="social-btn"><i class="fab fa-github"></i> GitHub</a>
                    <a href="https://twitter.com/mihirinamdar" target="_blank" class="social-btn"><i class="fab fa-twitter"></i> Twitter</a>
                </div>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; 2025 Mihir Inamdar. All rights reserved.</p>
        </div>
    </footer>

    <button id="scroll-top-btn" title="Go to top"><i class="fas fa-arrow-up"></i></button>

    <script src="main.js"></script>
</body>
</html>
